{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, ), (0.5, ))\n",
    "    ]\n",
    ")\n",
    "trainset = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=100,  # minibatchのbatch size\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "testset = datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=100,\n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3) # 28x28x1 -(3x3x32)-> 26x26x32  # 2D convolution\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3) # 26x26x32 -(3x3x2)-> 24x24x64  # 2D convolution\n",
    "        self.pool = nn.MaxPool2d(2, 2) # 24x24x64 -> 12x12x64\n",
    "        self.fc1 = nn.Linear(12 * 12 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.dropout05 = nn.Dropout2d() # default: p = 0.5\n",
    "        self.dropout02 = nn.Dropout2d(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.dropout02(x) # 入力層はdropout ratio: 0.2\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        self.dropout02(x) # 全結合層以外はdropout ratio: 0.2\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        self.dropout05(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 12 * 12 * 64)\n",
    "        self.dropout05(x)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        self.dropout05(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Start Training\n",
      "[ 1,   100] loss:  1.210\n",
      "[ 1,   200] loss:  0.331\n",
      "[ 1,   300] loss:  0.237\n",
      "[ 1,   400] loss:  0.188\n",
      "[ 1,   500] loss:  0.150\n",
      "[ 1,   600] loss:  0.126\n",
      "[ 2,   100] loss:  0.101\n",
      "[ 2,   200] loss:  0.098\n",
      "[ 2,   300] loss:  0.086\n",
      "[ 2,   400] loss:  0.081\n",
      "[ 2,   500] loss:  0.071\n",
      "[ 2,   600] loss:  0.067\n",
      "[ 3,   100] loss:  0.061\n",
      "[ 3,   200] loss:  0.060\n",
      "[ 3,   300] loss:  0.060\n",
      "[ 3,   400] loss:  0.052\n",
      "[ 3,   500] loss:  0.051\n",
      "[ 3,   600] loss:  0.055\n",
      "[ 4,   100] loss:  0.042\n",
      "[ 4,   200] loss:  0.048\n",
      "[ 4,   300] loss:  0.040\n",
      "[ 4,   400] loss:  0.043\n",
      "[ 4,   500] loss:  0.044\n",
      "[ 4,   600] loss:  0.039\n",
      "[ 5,   100] loss:  0.032\n",
      "[ 5,   200] loss:  0.030\n",
      "[ 5,   300] loss:  0.034\n",
      "[ 5,   400] loss:  0.036\n",
      "[ 5,   500] loss:  0.036\n",
      "[ 5,   600] loss:  0.040\n",
      "Finished Training\n",
      "Accuracy: 98.60 %\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    epochs = int(input())\n",
    "    \n",
    "    net = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(\n",
    "        net.parameters(),\n",
    "        lr=0.01,  # 学習係数\n",
    "        momentum=0.8,  # 慣性係数\n",
    "        nesterov=True  \n",
    "    )\n",
    "    \n",
    "    print('Start Training')\n",
    "    \n",
    "    net.train() # train modeに設定\n",
    "    for epoch in range(1, epochs+1):\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(trainloader, 1):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs) # forwardメソッドが実行され、Tensorオブジェクトとして出力される。\n",
    "            loss = criterion(outputs, labels) # outputsとlabelsからloss funcを計算してTensorオブジェクトとして返される。\n",
    "            loss.backward()　#  loss.item()から各parameterの勾配を計算して、parameter.gradに記憶する。\n",
    "                                         # lossはTensorオブジェクトでgrad_fnアトリビュートから全parameterを追跡できる。\n",
    "                                         # このgrad_fnの値はoutputsに記憶されていたものでoutputsから渡される。\n",
    "            optimizer.step() # parameter.gradを利用してparameterを更新\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:\n",
    "                print(f'[{epoch: d}, {i: 5d}] loss: {running_loss/100: .3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    net.eval() # eval modeに設定。dropoutがdeactivateされる\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in testloader:\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy: {:.2f} %'.format(100 * float(correct/total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10f79f9e8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "images, labels = iter(trainloader).next()\n",
    "plt.imshow(images[0].numpy().reshape(28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
